---
title: "Assignment 1"
author: "Marine Courtin"
date: "23 septembre 2017"
output: html_document
---

## Exercise 1

RMarkdown files are pretty neat because they allow you to include in a single document the R code you wrote, some explanations about the code, and the output of the code (plots for example).

## Exercise 2

```{r}
possible_outcomes <- c(0, 1, 2, 3, 4, 5)
outcome_probabilities <- c(0.1, 0.5, 0.2, 0.1, 0.05, 0.05)
n_data_points <- 400

set.seed(1)
fake_data_points <- sample(possible_outcomes,
                           n_data_points,
                           replace=T,
                           prob=outcome_probabilities)
set.seed(NULL)

fake_data_set <- tibble::data_frame(`Fake measurement`=fake_data_points)
```

+ __Statement 1.__ We've already established that the 1st line creates a variable called *possible_outcomes*, and assigns it a vector as value. This vector contains the range of our possible outcomes (from 0 to 5). 

+ __Statement 2.__ *outcome_probabilities* stores another vector. Each element of this vector is a probability. 

Both of the vectors we've created have the same length : we can already guess that to each possible outcome will be attributed a probability.

+ __Statement 3.__ We attribute an integer to the variable *n_data_points*, this integer corresponds to the number of points we will want to generate and plot.

+ __Statement 4.__ For this line I looked up [some](https://stackoverflow.com/questions/13605271/reasons-for-using-the-set-seed-function) [informations](http://www.talkstats.com/showthread.php/16833-the-function-set.seed()-in-R?s=53d821a6e07022a37a95a1df83ba5ed6) on the `set.seed()` function. This function allows us to :
    1. generate random numbers (in the case of our future plot, we can think of it as blowing seeds to the wind and seeing where they land)
    2. reproduce the same random numbers by reusing the function with the same argument (which would be __highly__ unlikely if we just tried to re-generate new random numbers)
  

+ __Statement 5.__ We then use the `sample()` function to create some data. This function returns a list of values between 0 and 5, which we will assign to the *fake_data_points* variable, and takes 4 arguments as stated [here](http://www.endmemo.com/program/R/sample.php):

    1. our vector containing the possible outcomes
    2. a positive integer which corresponds to the number of points we want to create.
    3. *replace*, which takes a boolean as value (true in the example). To understand what this means, I tried the following :
        + changing T to F, which raised this error : Error in sample.int(length(x), size, replace, prob) : impossible de prendre un Ã©chantillon plus grand que la population lorsque 'replace = FALSE'
        + changing the number of data points to 3 (smaller than our population) : this gave me no insight whatsoever
        + googled it and found something on [this page](https://stats.stackexchange.com/questions/97512/sample-replace-f-in-r#97516) : we use replacement=T when the numbers we draw return to the pool of possible draws. This explains why we can't use replacement=F when our number of draws is larger than our population, as we would run out of numbers to draw.
    4. a vector specifying the probability of each event - by event here we mean "having the value x".
  

+ __Statement 6.__ We change the argument of `set.seed()` to NULL, which means that when we will generate new random numbers, they won't be the same as before (except for pure luck, which seems highly unlikely).


+ __Statement 7.__ *tibble* is a package. I know this, because as I am working on my own computer, I've had to install it before being able to run to code. I installed it running `install.packages("tibble")` in the console. To understand this command I tried to run `help("tibble")`. Based on the information i got and [this webpage](http://www.r-tutor.com/r-introduction/data-frame) I gathered that the command is used to store our data into a tibble data frame (which seems to be a more user friendly type of data frame than the one typically used in R). Running `fake_data_set` returned a table with 2 columns and 400 rows, each rank corresponds to one of our possible outcomes. This tibble data frame which stores our values seems to be entitled *Fake measurement*.


```{r, echo=FALSE}
ggplot2::ggplot(fake_data_set, ggplot2::aes(x=`Fake measurement`)) +
  ggplot2::geom_histogram(bins=5, colour="black", fill="lightgrey")
```


## Exercise 3

__Question 3.a__

```{r, echo=FALSE}
iris_groups23 <- dplyr::filter(iris, Species %in% c("versicolor", "virginica"))
ggplot2::ggplot(iris_groups23, ggplot2::aes(x=Sepal.Width)) +
  ggplot2::geom_histogram(colour="black", fill="lightgrey", binwidth=0.1) +
  ggplot2::facet_grid(Species ~ .)
```

Each histogram represents the number (count) of irises of a certain species having their sepal width in a specific interval. For example we read that 1 iris of the versicolor species has sepals measuring between 2.0cm (inclusive) to 2.1cm (non-inclusive). In the same way, we read that 12 irises of the virginica species have sepals measuring between 3.0cm and 3.1cm.

```{r, echo=FALSE}
library(magrittr)
iris_versicolor_subset <- dplyr::filter(iris,
                                        Sepal.Width <= 2.5,
                                        Species == "versicolor") %>%
                          dplyr::select(Sepal.Width, Species)
knitr::kable(iris_versicolor_subset)
```


Here is the drawing I did of this subset of the "versicolor" measurements :

```{r, echo=FALSE, out.width='70%', fig.align='center'}
knitr::include_graphics("drawing_3-a.jpg")
```


__Question 3.b__

Here are the bins I checked :

+ 2.5 : 4 *versicolors* + 4 *virginica* -> 8 irises in total (ok)
+ 2.6 : 3 *versicolors* + 2 *virginica* -> 5 irises in total (ok)
+ 3.5 : no *versicolor* nor *virginica* -> 0 iris in total (ok)
+ 3.8 : no *versicolor* 1 *virginica* -> 1 iris in total (ok)

So yes, as far as we know, the 2 small histograms seem to add up to the big one.

__Question 3.c__


We are trying to answer 3 questions : 

+ what is the sepal width of a versicolor iris ?
+ what is the sepal width of a virginica iris ?
+ do the two match up ?

The problem is that there is not one sepal width measure that can caracterize all irises belonging to the same species. Indeed, there are sources of variability (sun exposition, quantity of nutrients in the soil etc...) which explains why these measurements are distributed on a continuum (2.0-3.4cm for versicolor irises and 2.0-3.8cm for virginica irises in our data).

When we ask if the two species are the same in terms of sepal width, what we really want to know is wether the two species would have the same sepal width measurements if we took out that source of variability.
    
Here are the 2 possible hypotheses we might entertain :


+ __Hypothesis A__: The virginica and versicolor iris species are the same in terms of sepal width.

    
    According to this hypothesis, both species of irises share the same underlying pattern in terms of their sepal width. This doesn't mean that we will observe identical histograms (and in our data we don't), but rather that the differences we might pick up on in terms of the distribution of sepal width is based on the presence of a source of variability (sun exposition, quantity of nutrients in the soil etc...). If we continued our experiment and measured other irises, we would expect to see the differences between the two histograms get less prominent. For example, we might encounter a few versicolor irises with 3.5 to 3.8cm sepal width, and a few virginica irises with sepal width between 2.0 and 2.5cm.
    
+ __Hypothesis B__: The virginica and versicolor iris species are different in terms of sepal width.

    According to this second hypothesis, both species do not share the same underlying pattern in terms of their sepal width. We wouldn't expect to make similar observation on the sepal width with similar frequencies. If both our histograms looked similar for the two species, it would be pure luck, as the most probable outcome would be 2 distributions showing differences. For example if we did further measurements, we could expect to see more virginica irises with sepal width between 3.5 and 3.8, while there would still be none of these measurements for versicolor irises. We could then postulate that virginica irises reach higher sepal width more often than versicolor irises.


## Exercise 4

__Question 4.a__


Placement of the stress on *permit* (noun and verb) :

```{r, echo=FALSE}
ggplot2::ggplot(stressshift::stress_shift_permit,
                ggplot2::aes(x=Category, fill=Syllable)) +
  ggplot2::geom_bar(position="dodge", colour="black") + 
  ggplot2::scale_fill_brewer(palette="Set3")
```

Placement of the stress on *permit* (regardless of its part-of-speech) :

```{r, echo=FALSE}
ggplot2::ggplot(stressshift::stress_shift_permit, ggplot2::aes(x=0, fill=Syllable)) +
  ggplot2::geom_bar(position="dodge", colour="black") + 
  ggplot2::scale_fill_brewer(palette="Set3") +
  ggplot2::xlab("") +
  ggplot2::theme(axis.text.x=ggplot2::element_blank(),
                 axis.ticks.x=ggplot2::element_blank()) +
  ggplot2::xlim(c(-1,1))
```

+ __Hypothesis A__: Permit (noun) and permit (verb) are the same in terms of their stress:

    According to this hypothesis permit(noun) and permit(verb) share the same underlying pattern of accentuation. This means that we would most likely expect them to have similar distributions in the placement of the stress. To be more specific, we would expect the distribution to look somewhat like that of the second figure, which would give us around 18 occurences of the stress on the 1st syllable and 28 occurences of the stress on the 2nd syllable. Of course we could find some variations (14 1st syllable occurences for noun and 22 for verb for example), but if the noun and verb share the same underlying pattern, observing extreme differences between their distributions would have a low probability.
  
+ __Hypothesis B__: Permit (noun) and permit (verb) are different in terms of their stress.

    According to this hypothesis permit(noun) and permit(verb) do not share the same underlying pattern of accentuation. For the both of them to have similar distributions of stress placement would not be very probably. Instead, we would expect to see differences between the frequencies of their stress placement and the global frequency of the stress placement for the word *permit* regardless of its part-of-speech. 

__Question 4.b__

I'm going to argue that __permit (noun) and permit (verb) are different in terms of their stress__.

The verb *permit* is - by far - mostly stressed on its 2nd syllable. On the other hand, the situation is not as clear cut for the noun : the 1st syllable is more frequently stressed but there are some occurences of a 2nd syllable stress as well. In any case, both realizations of *permit* share __different - verging on reverse - patterns of distribution__.

The dictionaries used in this study date back to the 17th century which is a useful information that we will take into consideration. As far as I am aware, the noun *permit* is more recent than the verb, from which it derived. This could mean that when the noun was introduced in dictionaries, the verb already had a __"stable" stress pattern__ (namely, a 2nd syllable stress). In the beginning, the noun might have shared this pattern, and then went through a process of change in terms of stress, so that its use could be __contrasted with the use of the verb__. This different stress pattern would be used to signal that the noun does not share the same combinatorial principles as the verb (i.e verb and noun play different roles and therefore are used in different syntactic contexts). Therefore when permit first began to be used as a noun it would have started out with a 2nd syllable stress just like the verb it derived from (which might explain we find some traces of this 2nd syllable stress in our permit(noun) data), and then gradually acquired a 1st syllable stress instead as its different use in syntax was observed.

## Exercise 5


__Question 5a.__

```{r, echo=FALSE}
library(magrittr)
set.seed(1)
ver_balanced <- languageR::ver %>%
  dplyr::group_by(SemanticClass) %>%
  dplyr::sample_n(198)
set.seed(NULL)
```

```{r, echo=FALSE}
ggplot2::ggplot(ver_balanced, ggplot2::aes(x=Frequency)) +
  ggplot2::geom_histogram(fill="lightgrey", colour="black", binwidth=250) +
  ggplot2::facet_grid(SemanticClass ~ .)
```

We are now observing this histogram of count data. The figure is composed of 2 subplot : the 1st one concerns semantically opaque Dutch verbs containing the prefix *ver-*, while the second represents semantically transparent Dutch verbs containing the prefix *ver-* from our corpus. There are 198 observations in each of these two groups. Each bar stands for the number of verbs (opaque for the top and transparent at the bottom) having x occurences where x [y:y+250[. For example if we look at the bottom subplot and specifically the second bar from the left, we find out that there are 25 semantically transparent Dutch verbs using the prefix *ver-* wich have a number of occurences between 250 (included) and 500 (not included).

The 2 types of counts are therefore :

+ count (y-axis) : number of verbs
+ "frequency" (x-axis) : number of occurences of the verb 


__Question 5b.__

We now wish to discuss 2 hypotheses :

+ __Hypothesis A__ : Semantically transparent and opaque *ver-* verbs are the same in terms of their frequency.

    If this hypothesis is verified, we would expect the two subplots to look somewhat similar, with similar counts of verbs having similar frequencies for both semantically transparent and semantically opaque verbs. In our case this would mean pretty high counts of low frequency verbs and lower counts of high frequency verbs. We could still observe some differences in the two distributions caused by an exterior source of variability.

+ __Hypothesis B__ : Semantically transparent and opaque *ver-* verbs are different in terms of their frequency.

    If this hypothesis is verified, we would expect the two subplots to show differences in the underlying patterns. In our case this would probably mean :

    + For semantically transparent verbs, really high counts of low frequency verbs, practically no verbs with higher frequencies.

    + For semantically opaque verbs, mid-range counts of low frequency verbs, presence of low counts of higher frequency verbs


__Question 5c.__